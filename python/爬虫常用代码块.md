##### 保存到文件
```python
def save_page(list_article,filename):
    """
    保存到文件
    :param list_article: 结果
    :param filename: 保存的文件名
    """
    dir_save_page = sys.path[0] + '/bio360_spider_result/'
    if not os.path.exists(dir_save_page):
        os.makedirs(dir_save_page)
    try:
        with open(dir_save_page + filename , 'w', encoding = 'utf-8') as f:
            for i in list_article:
                f.write(i)
    except  OSError as e:
        print('内容保存失败：' + filename + '\n{e}'.format(e = e))
```


##### 获取文章中所有的图片
```python
        # 获取文章中所有的图片url链接: http://www.bio360.net/storage/image/2018/08/FG3XNGQGmD2HxBMqFgNNmiuLNXjTWHU9cnblI8TV.png
        pattern_img = re.compile(r'<img(.*?)\ssrc="(.*?)"', re.I)
        findall_img = pattern_img.findall(source_article)
        for kw in findall_img:
            # kw[1]: http://www.bio360.net/storage/image/2018/08/FG3XNGQGmD2HxBMqFgNNmiuLNXjTWHU9cnblI8TV.png
            # 判断图片URL是否需要组合
            pattern_judge_img = re.compile(r'http', re.I)
            judge_img = pattern_judge_img.search(kw[1])
            if judge_img:
                url_full_img = kw[1]
            else:
                url_full_img =  'http://www.bio360.net' + kw[1]

            # 图片保存名：dwNNY7cwzRcOcsjRwMFcceLF9qTvhyDP8HiHTgQc.png
            pattern_name_save_img = re.compile(r'.*\/(.*\.[jpbg][pmin]\w+)', re.I)
            try:
                name_save_img = pattern_name_save_img.search(kw[1]).group(1)
                # 获取图片
                response_img = requests.get(url_full_img, headers = headers).content

                # 保存图片
                save_img(response_img, name_save_img)

            except:
                print('图片网址有误:' + url_full_img)
```

##### 获取文章内容写入为xml文件
```python
def parse_page(source_local):
    """
    提取文章内容
    :param source_local: 文章内容
    """
    # 需要的内容保存到列表里，写入为.xml文件
    list_article = []
    list_article.append('<Document>')

    # 利用etree.HTML，将字符串解析为HTML文档
    html_source_local = etree.HTML(source_local) 
    # print(type(html_source_local),html_source_local)

    # title_article: 第四届发育和疾病的表观遗传学上海国际研讨会在沪隆重开幕
    title_article = html_source_local.xpath('//div[@id = "caption"]')[0].text
    title_article = '<title>' + title_article + '</title>\n'
    list_article.append(title_article)
    # print(type(title_article),title_article)

    # source_article：来源： 中科普瑞 / 作者：  2018-09-11
    source_article = html_source_local.xpath('//div[@id = "date"]')[0].text
    source_article = '<source>' + source_article + '</source>\n'
    list_article.append(source_article)
    # print(type(source_article),source_article)

    # 通过正则表达式获取文章中需要的内容，即正文部分
    pattren_article_content = re.compile(r'<div id="nr">(.*)<script type="text/javascript">', re.I|re.S)
    source_article = pattren_article_content.search(source_local)

    if source_article:
        source_article = source_article.group(1)

    def img_url_name(match):
        """
            匹配文章内容中的图片url，替换为本地url
            """
            # http://www.bio360.net/storage/image/2018/08/FG3XNGQGmD2HxBMqFgNNmiuLNXjTWHU9cnblI8TV.png
            pattren_img_local = re.compile(r'\.[pjbg][pinm]', re.I)
            img_real_name = pattren_img_local.search(match.group())
            # print('match.group(1)', match.group())

            if img_real_name and match.group(1):
                pattern_kw_name_save_img = re.compile(r'.*\/(.*\.[jpbg][pmin]\w+)', re.I)
                kw_img_name = pattern_kw_name_save_img.search(match.group(1)).group(1)
                img_name = '<img src="./img/' + kw_img_name + '" />'
                # print('img_name:', type(img_name), img_name)
                return img_name

        # 匹配文章内容中的图片url，替换为本地图片url
        pattren_img_local = re.compile(r'<img.*?\ssrc="(.*?)".*?>{1}', re.I|re.S)
        source_local = pattren_img_local.sub(url_img_name, source_article)

    # 剔除文章中不需要的内容
    def article_change(match):
        """
        匹配文章内容中的所有标签（a、img、p）除外，剔除掉
        """
        # <p src="./img/13SsuHuXECVJ<p style="text-align: center;"> p
        # print(match.group(),match.group(1))
        name_tag = ''
        return name_tag

    pattren_article_change = re.compile(r'<([^/aip]\w*)\s*.*?>{1}')
    source_local = pattren_article_change.sub(article_change, source_article)

    # 剔除所有除</p>外的</>标签
    pattren_article_change_1 = re.compile(r'</[^p].*?>{1}')
    source_local = pattren_article_change_1.sub('', source_local)

    # 剔除<P>标签的样式
    pattren_article_change_2 = re.compile(r'<p.*?>{1}')
    source_local = pattren_article_change_2.sub('<p>', source_local)

    # 剔除一些杂乱的样式
    source_local = source_local.replace('&nbsp;','').strip().replace('&','&amp;')

    # 清洗后的正文
    print(source_local)
    source_local = '<content>\n' + source_local + '</content>\n'
    list_article.append(source_local)
    list_article.append('</Document>')

    return list_article

```